{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXJFCHOZ5Ksu"
      },
      "outputs": [],
      "source": [
        "!pip install --pre deepchem\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib\n",
        "from matplotlib import font_manager\n",
        "from sklearn.decomposition import PCA\n",
        "# Create the directory for fonts if it doesn't exist\n",
        "font_dir = \"/content/fonts\"\n",
        "os.makedirs(font_dir, exist_ok=True)\n",
        "\n",
        "# Download the font\n",
        "font_url = \"https://github.com/sshaghayeghs/molSMILES/raw/main/Times_New_Roman.ttf\"\n",
        "font_path = os.path.join(font_dir, \"times_new_roman.ttf\")\n",
        "if not os.path.exists(font_path):\n",
        "    os.system(f\"wget -P {font_dir} {font_url}\")\n",
        "\n",
        "# Add the font to Matplotlib\n",
        "font_files = font_manager.findSystemFonts(fontpaths=[font_dir])\n",
        "for font_file in font_files:\n",
        "    font_manager.fontManager.addfont(font_file)\n",
        "\n",
        "# Verify the font is recognized by Matplotlib\n",
        "font_name = \"Times New Roman\"\n",
        "if font_name in font_manager.get_font_names():\n",
        "    print(f\"'{font_name}' font successfully added.\")\n",
        "    # Set default font to Times New Roman\n",
        "    matplotlib.rc('font', family=font_name)\n",
        "else:\n",
        "    print(f\"'{font_name}' font not found. Please check the font installation.\")"
      ],
      "metadata": {
        "id": "p9M6-b7M5QJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, precision_recall_curve, auc,mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LogisticRegression,Ridge\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.exceptions import NotFittedError\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "def load_emb(dataset, language_model, dataset_path=None, embedding_path=None):\n",
        "    df = pd.read_csv(f\"{dataset_path}{dataset}.csv\")\n",
        "    features_df = pd.read_csv(f\"{embedding_path}{dataset}_{language_model}.csv\")\n",
        "    if 'Unnamed: 0' in features_df.columns:\n",
        "        features_df = features_df.drop(columns=['Unnamed: 0'])\n",
        "    targets = df.drop(columns=['SMILES']).to_numpy()\n",
        "    features = features_df.to_numpy()\n",
        "    ids = df['SMILES'].tolist()\n",
        "    return features, targets\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_classification(features, targets, n_splits, task):\n",
        "    # K-fold cross-validation setup\n",
        "    if task == 'MultitaskClassification':\n",
        "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    else:\n",
        "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "    f1_scores = []\n",
        "    aucrocs = []\n",
        "    for train_index, test_index in kf.split(features, targets if task != 'MultitaskClassification' else None):\n",
        "        X_train, X_test = features[train_index], features[test_index]\n",
        "        y_train, y_test = targets[train_index], targets[test_index]\n",
        "\n",
        "        if task == 'Classification':\n",
        "            model = LogisticRegression(max_iter=500)\n",
        "            model.fit(X_train, y_train.ravel())  # Assuming y_train is not multilabel\n",
        "            y_test_pred = model.predict(X_test)\n",
        "            y_test_proba = model.predict_proba(X_test)[:, 1]\n",
        "        elif task == 'MultitaskClassification':\n",
        "            model = MultiOutputClassifier(LogisticRegression(max_iter=500))\n",
        "            model.fit(X_train, y_train)\n",
        "            y_test_pred = model.predict(X_test)\n",
        "            try:\n",
        "                y_test_proba = np.array([est.predict_proba(X_test)[:, 1] for est in model.estimators_]).T\n",
        "            except NotFittedError:\n",
        "                print(\"Model not fitted or single output model predict_proba called\")\n",
        "                continue\n",
        "\n",
        "        [f1, aucroc] = get_results(y_test, y_test_pred, y_test_proba, task)\n",
        "        f1_scores.append(f1)\n",
        "        aucrocs.append(aucroc)\n",
        "\n",
        "\n",
        "    return [np.mean(f1_scores),np.std(f1_scores),np.mean(aucrocs),np.std(aucrocs)]\n",
        "\n",
        "def get_results(test_labels, y_pred, y_pred_proba, task):\n",
        "    if task == 'MultitaskClassification':\n",
        "        # Calculate metrics for multilabel data\n",
        "        prec = precision_score(test_labels, y_pred, average='macro')\n",
        "        recall = recall_score(test_labels, y_pred, average='macro')\n",
        "        f1 = f1_score(test_labels, y_pred, average='macro')\n",
        "\n",
        "        aucrocs = []\n",
        "        for i in range(test_labels.shape[1]):\n",
        "            if len(np.unique(test_labels[:, i])) > 1:  # only if there are both classes present\n",
        "                aucrocs.append(roc_auc_score(test_labels[:, i], y_pred_proba[:, i]))\n",
        "        aucroc = np.mean(aucrocs)\n",
        "\n",
        "        precisions, recalls, _ = precision_recall_curve(test_labels.ravel(), y_pred_proba.ravel())\n",
        "        aupr = auc(recalls, precisions)\n",
        "    else:\n",
        "        # Binary classification metrics\n",
        "        prec = precision_score(test_labels, y_pred)\n",
        "        recall = recall_score(test_labels, y_pred)\n",
        "        f1 = f1_score(test_labels, y_pred)\n",
        "        aucroc = roc_auc_score(test_labels, y_pred_proba)\n",
        "        p, r, _ = precision_recall_curve(test_labels, y_pred_proba)\n",
        "        aupr = auc(r, p)\n",
        "\n",
        "    return [f1, aucroc]\n",
        "def evaluate_regression(features, targets, n_splits=5):\n",
        "    # Set up KFold cross-validation\n",
        "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    r2_scores = []\n",
        "    rmse_scores = []\n",
        "\n",
        "    for train_index, test_index in kf.split(features):\n",
        "        X_train, X_test = features[train_index], features[test_index]\n",
        "        y_train, y_test = targets[train_index], targets[test_index]\n",
        "\n",
        "        # Model training\n",
        "        model = Ridge()\n",
        "        model.fit(X_train, y_train.ravel())  # Ensure y_train is properly shaped\n",
        "\n",
        "        # Prediction and performance evaluation\n",
        "        y_pred = model.predict(X_test)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "        # Store the scores\n",
        "        r2_scores.append(r2)\n",
        "        rmse_scores.append(rmse)\n",
        "\n",
        "    return [np.mean(rmse_scores),np.std(rmse_scores), np.mean(r2_scores),np.std(rmse_scores)]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oBQzJDZr5UoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features, targets = load_emb('freesolv', 'morgan',dataset_path,embedding_path)\n",
        "\n",
        "results = evaluate_regression(features, targets, 5)\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "b5pdRLoN5ZXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_path = '/content/drive/MyDrive/Shaghayegh Sadeghi/Drug embedding/LLaMA Vs GPT/'\n",
        "dataset_path = '/content/drive/MyDrive/Shaghayegh Sadeghi/Drug embedding/LLaMA Vs GPT/dataset/'\n",
        "# Data initialization\n",
        "datasets = ['bace_classification','bbbp','clintox','sider','tox21','hiv','freesolv', 'lipo', 'delaney']\n",
        "models = ['morgan', 'bert', 'GPT','llama-7B','llama2-7B','ChemBERTa', 'molformer']\n",
        "classification_results = []\n",
        "regression_results = []\n",
        "\n",
        "\n",
        "for dataset in datasets:\n",
        "  for model in models:\n",
        "    print(f\"Evaluating {dataset} with {model}...\")\n",
        "    features, targets = load_emb(dataset, model,dataset_path,embedding_path)\n",
        "    if dataset in ['bbbp', 'bace_classification', 'hiv']:\n",
        "      f1,std_f1, aucroc,std_aucroc= evaluate_classification(features, targets, 5, 'Classification')\n",
        "      classification_results.append({'Dataset': dataset, 'Model': model, 'F1_Score':round(f1, 3),'Std_F1_Score':round(std_f1, 3),'AUROC':round(aucroc, 3),'Std_AUROC':round(std_aucroc, 3)})\n",
        "    elif dataset in ['sider', 'clintox', 'tox21']:\n",
        "        f1,std_f1, aucroc,std_aucroc= evaluate_classification(features, targets, 5, 'MultitaskClassification')\n",
        "        classification_results.append({'Dataset': dataset, 'Model': model, 'F1_Score':round(f1, 3),'Std_F1_Score':round(std_f1, 3),'AUROC':round(aucroc, 3),'Std_AUROC':round(std_aucroc, 3)})\n",
        "    elif dataset in ['freesolv', 'lipo', 'delaney']:\n",
        "        RMSE,std_RMSE,r2,std_r2 = evaluate_regression(features, targets, 5)\n",
        "        regression_results.append({'Dataset': dataset, 'Model': model, 'RMSE': round(RMSE, 3),'Std_RMSE': round(std_RMSE, 3),'R2':round(r2, 3),'Std_R2': round(std_r2, 3),})\n",
        "\n",
        "\n",
        "# Convert lists to DataFrames\n",
        "classification_result = pd.DataFrame(classification_results)\n",
        "regression_result = pd.DataFrame(regression_results)"
      ],
      "metadata": {
        "id": "0nbwQTsv5fBy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}